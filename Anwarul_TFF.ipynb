{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Update Scipy and other libraries\n",
        "!pip install --upgrade scipy tensorflow tensorflow-federated pandas scikit-learn cryptography google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLSdck3G2hHb",
        "outputId": "9b9460f1-7a5b-4804-da21-5b3ba8c0d8bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.9.3)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.1)\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: tensorflow-federated in /usr/local/lib/python3.10/dist-packages (0.84.0)\n",
            "Collecting tensorflow-federated\n",
            "  Using cached tensorflow_federated-0.86.0-py3-none-manylinux_2_31_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (43.0.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.34.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Collecting google-auth-oauthlib\n",
            "  Using cached google_auth_oauthlib-1.2.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.143.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n",
            "  Using cached ml_dtypes-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (22.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
            "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.2.0 (from tensorflow)\n",
            "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: attrs~=23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (23.1.0)\n",
            "Requirement already satisfied: cachetools~=5.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (5.5.0)\n",
            "Requirement already satisfied: dm-tree==0.1.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.1.8)\n",
            "Requirement already satisfied: dp-accounting==0.4.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.4.3)\n",
            "Requirement already satisfied: google-vizier==0.1.11 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.1.11)\n",
            "Requirement already satisfied: jaxlib==0.4.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.4.14)\n",
            "Requirement already satisfied: jax==0.4.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.4.14)\n",
            "INFO: pip is looking at multiple versions of tensorflow-federated to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-federated\n",
            "  Using cached tensorflow_federated-0.85.0-py3-none-manylinux_2_31_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: portpicker~=1.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (1.6.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization==0.7.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.7.5)\n",
            "Requirement already satisfied: tensorflow-privacy==0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (0.9.0)\n",
            "Requirement already satisfied: tqdm~=4.64 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (4.66.5)\n",
            "Requirement already satisfied: googleapis-common-protos==1.61.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-federated) (1.61.0)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.10/dist-packages (from dp-accounting==0.4.3->tensorflow-federated) (1.3.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.35.0 in /usr/local/lib/python3.10/dist-packages (from google-vizier==0.1.11->tensorflow-federated) (1.62.3)\n",
            "Requirement already satisfied: sqlalchemy<=1.4.20,>=1.4 in /usr/local/lib/python3.10/dist-packages (from google-vizier==0.1.11->tensorflow-federated) (1.4.20)\n",
            "Requirement already satisfied: tensorflow-probability~=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-privacy==0.9.0->tensorflow-federated) (0.22.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography) (1.17.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.19.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography) (2.22)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.24.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.1.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker~=1.6->tensorflow-federated) (5.9.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<=1.4.20,>=1.4->google-vizier==0.1.11->tensorflow-federated) (3.0.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow-federated) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.22.0->tensorflow-privacy==0.9.0->tensorflow-federated) (2.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_federated as tff\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from cryptography.hazmat.backends import default_backend\n",
        "from cryptography.hazmat.primitives import hashes\n",
        "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n",
        "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
        "import os\n",
        "import numpy as np\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from google.auth.transport.requests import Request\n",
        "import google.auth\n",
        "import base64\n",
        "\n",
        "# Authenticate and create the Google Drive client\n",
        "print(\"Authenticating and creating Google Drive client...\")\n",
        "print(\"Client : Anwarul\")\n",
        "auth.authenticate_user()\n",
        "creds, _ = google.auth.default()\n",
        "if creds.expired and creds.refresh_token:\n",
        "    creds.refresh(Request())\n",
        "print(\"Authentication successful. Connected to Google Drive.\")\n",
        "\n",
        "drive_service = build('drive', 'v3', credentials=creds)\n",
        "print(\"Google Drive is set as the global server.\")\n",
        "\n",
        "# Load the dataset directly from the uploaded file\n",
        "data_path = '/content/johns_hospital_data.csv'  # Change filename as needed\n",
        "print(f\"Loading dataset from {data_path}...\")\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Data Preprocessing\n",
        "print(\"Starting data preprocessing...\")\n",
        "data_cleaned = data.drop(['Admission_date', 'hospital_name', 'patient_id',\n",
        "                         'patient_first_initial', 'patient_last_name',\n",
        "                         'doctor_name', 'patient_checkin_date', 'patient_checkout_date'], axis=1)\n",
        "\n",
        "# Convert categorical columns to numerical using Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_columns = data_cleaned.select_dtypes(include=['object']).columns\n",
        "\n",
        "for column in categorical_columns:\n",
        "    data_cleaned[column] = label_encoder.fit_transform(data_cleaned[column])\n",
        "\n",
        "# Define features and target variable\n",
        "X = data_cleaned.drop('readmission', axis=1)\n",
        "y = data_cleaned['readmission']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"Data split into training and testing sets.\")\n",
        "\n",
        "# Standardize the dataset\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to TensorFlow Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32)\n",
        "\n",
        "# Prepare the dataset for federated learning\n",
        "def preprocess(dataset):\n",
        "    return dataset.map(lambda x, y: (tf.cast(x, tf.float32), tf.cast(y, tf.int32))) \\\n",
        "                  .map(lambda x, y: (x, tf.expand_dims(y, -1)))\n",
        "\n",
        "train_dataset = preprocess(train_dataset)\n",
        "print(\"Data preprocessing completed successfully.\")\n",
        "\n",
        "# Define the model function for Federated Learning\n",
        "def create_keras_model():\n",
        "    return tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),  # Ensure input shape is correct\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification output\n",
        "    ])\n",
        "\n",
        "def model_fn():\n",
        "    keras_model = create_keras_model()\n",
        "    return tff.learning.models.from_keras_model(\n",
        "        keras_model,\n",
        "        input_spec=(tf.TensorSpec(shape=[None, X_train.shape[1]], dtype=tf.float32),\n",
        "                    tf.TensorSpec(shape=[None, 1], dtype=tf.int32)),\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "print(\"Model function defined successfully.\")\n",
        "\n",
        "# Homomorphic Encryption Setup\n",
        "def get_aes_key(password: bytes, salt: bytes) -> bytes:\n",
        "    # Generate a key for homomorphic encryption using PBKDF2\n",
        "    kdf = PBKDF2HMAC(\n",
        "        algorithm=hashes.SHA256(),\n",
        "        length=32,  # Key length of 256 bits\n",
        "        salt=salt,\n",
        "        iterations=100000,\n",
        "        backend=default_backend()\n",
        "    )\n",
        "    return kdf.derive(password)\n",
        "\n",
        "def encrypt_weights(weights, password: bytes):\n",
        "    salt = os.urandom(16)  # Generate a random salt\n",
        "    encrypted_weights = []\n",
        "\n",
        "    print(\"Encrypting model weights...\")\n",
        "    for w in weights:\n",
        "        data = w.flatten().tobytes()\n",
        "        iv = os.urandom(16)  # Generate a random initialization vector\n",
        "        cipher = Cipher(algorithms.AES(get_aes_key(password, salt)), modes.CFB(iv), backend=default_backend())\n",
        "        encryptor = cipher.encryptor()\n",
        "        encrypted_data = iv + encryptor.update(data) + encryptor.finalize()  # Prepend IV\n",
        "        encrypted_weights.append((salt, encrypted_data))\n",
        "\n",
        "    print(\"Model weights encrypted successfully.\")\n",
        "    return encrypted_weights\n",
        "\n",
        "def decrypt_weights(encrypted_weights, password: bytes):\n",
        "    decrypted_weights = []\n",
        "\n",
        "    print(\"Decrypting model weights...\")\n",
        "    for salt, encrypted_data in encrypted_weights:\n",
        "        key = get_aes_key(password, salt)\n",
        "        iv = encrypted_data[:16]  # Extract the IV from the beginning\n",
        "        cipher = Cipher(algorithms.AES(key), modes.CFB(iv), backend=default_backend())\n",
        "        decryptor = cipher.decryptor()\n",
        "        decrypted_data = decryptor.update(encrypted_data[16:]) + decryptor.finalize()  # Decrypt data without IV\n",
        "        decrypted_weights.append(np.frombuffer(decrypted_data, dtype=np.float32))\n",
        "\n",
        "    print(\"Model weights decrypted successfully.\")\n",
        "    return decrypted_weights\n",
        "\n",
        "# Example of encrypting model weights\n",
        "password = b'my_secret_password'  # Set a strong password\n",
        "model_weights = create_keras_model().get_weights()\n",
        "encrypted_weights = encrypt_weights([w.flatten() for w in model_weights], password)\n",
        "\n",
        "# Decrypt weights when needed\n",
        "decrypted_weights = decrypt_weights(encrypted_weights, password)\n",
        "\n",
        "# Reshape the decrypted weights to match the original shapes\n",
        "decrypted_weights = [w.reshape(original_w.shape) for w, original_w in zip(decrypted_weights, model_weights)]\n",
        "print(\"Model weights encryption and decryption completed successfully.\")\n",
        "\n",
        "# Proceed with federated learning setup\n",
        "try:\n",
        "    print(\"Building federated averaging process...\")\n",
        "    client_optimizer_fn = lambda: tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "    iterative_process = tff.learning.algorithms.build_weighted_fed_avg(\n",
        "        model_fn=model_fn,\n",
        "        client_optimizer_fn=client_optimizer_fn\n",
        "    )\n",
        "    state = iterative_process.initialize()\n",
        "    print(\"Federated averaging process initialized successfully.\")\n",
        "\n",
        "    # Indicating connection between clients and global server\n",
        "    print(\"Clients are connected to the global server for federated learning.\")\n",
        "\n",
        "    # Perform multiple rounds of federated learning\n",
        "    for round_num in range(1, 11):\n",
        "        print(f\"Starting round {round_num} of federated learning...\")\n",
        "        state, metrics = iterative_process.next(state, [train_dataset])\n",
        "        print(f'Round {round_num} metrics: {metrics}')\n",
        "\n",
        "    print(\"Federated learning rounds completed successfully.\")\n",
        "except AttributeError as ae:\n",
        "    print(\"AttributeError:\", ae)\n",
        "except Exception as e:\n",
        "    print(\"An error occurred:\", e)\n",
        "\n",
        "# Save Model Updates to Google Drive in the new Keras format\n",
        "save_path = '/tmp/Anwarul_model_updates.keras'\n",
        "model_to_save = create_keras_model()  # Create the model\n",
        "model_to_save.set_weights(decrypted_weights)  # Set weights if using encryption\n",
        "model_to_save.save(save_path)\n",
        "print(f\"Model saved locally at {save_path}.\")\n",
        "\n",
        "file_metadata = {\n",
        "    'name': 'Anwarul_model_updates.keras',\n",
        "    'parents': ['1WVQMK27bObX0N0hDntjz1peL8bTHvsi7']  # Your global server folder ID\n",
        "}\n",
        "media = MediaFileUpload(save_path, mimetype='application/octet-stream')\n",
        "uploaded_file = drive_service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
        "print(f\"Model saved to Google Drive with ID: {uploaded_file.get('id')}.\")\n",
        "\n",
        "# Load Model Updates\n",
        "loaded_model = tf.keras.models.load_model(save_path)\n",
        "loaded_weights = loaded_model.get_weights()\n",
        "print(\"Loaded model weights from Google Drive.\")\n",
        "\n",
        "# Comparing Loaded and Decrypted Weights\n",
        "def compare_weights(loaded_weights, decrypted_weights):\n",
        "    if len(loaded_weights) != len(decrypted_weights):\n",
        "        return False\n",
        "    for lw, dw in zip(loaded_weights, decrypted_weights):\n",
        "        if lw.shape != dw.shape or not np.allclose(lw, dw, rtol=1e-5, atol=1e-8):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "if compare_weights(loaded_weights, decrypted_weights):\n",
        "    print(\"Weights loaded correctly and match the saved weights.\")\n",
        "else:\n",
        "    print(\"Discrepancy found in loaded weights.\")\n",
        "\n",
        "# List files in the global server folder\n",
        "results = drive_service.files().list(\n",
        "    q=f\"'1WVQMK27bObX0N0hDntjz1peL8bTHvsi7' in parents\",\n",
        "    pageSize=10, fields=\"files(id, name)\").execute()\n",
        "items = results.get('files', [])\n",
        "\n",
        "if not items:\n",
        "    print(\"No files found in the global server folder.\")\n",
        "else:\n",
        "    print(\"Files found in the global server folder:\")\n",
        "    for item in items:\n",
        "        print(f\"{item['name']} ({item['id']})\")\n",
        "\n",
        "# Privacy measure function to ensure privacy is preserved\n",
        "def privacy_measure(original_weights, encrypted_weights):\n",
        "    original_sum = sum(np.sum(w) for w in original_weights)\n",
        "    decrypted_weights = decrypt_weights(encrypted_weights, password)\n",
        "    decrypted_sum = sum(np.sum(w) for w in decrypted_weights)\n",
        "\n",
        "    if original_sum == decrypted_sum:\n",
        "        print(\"Privacy is preserved!!\")\n",
        "    else:\n",
        "        print(\"Privacy is compromised!!\")\n",
        "\n",
        "privacy_measure(model_weights, encrypted_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbPzIOAYUmql",
        "outputId": "f2e2a1b9-8ae0-4306-c8ba-4e474842d252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticating and creating Google Drive client...\n",
            "Client : Anwarul\n",
            "Authentication successful. Connected to Google Drive.\n",
            "Google Drive is set as the global server.\n",
            "Loading dataset from /content/johns_hospital_data.csv...\n",
            "Starting data preprocessing...\n",
            "Data split into training and testing sets.\n",
            "Data preprocessing completed successfully.\n",
            "Model function defined successfully.\n",
            "Encrypting model weights...\n",
            "Model weights encrypted successfully.\n",
            "Decrypting model weights...\n",
            "Model weights decrypted successfully.\n",
            "Model weights encryption and decryption completed successfully.\n",
            "Building federated averaging process...\n",
            "Federated averaging process initialized successfully.\n",
            "Clients are connected to the global server for federated learning.\n",
            "Starting round 1 of federated learning...\n",
            "Round 1 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.526125), ('loss', 0.6998043), ('num_examples', 8000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Starting round 2 of federated learning...\n",
            "Round 2 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.576125), ('loss', 0.6838501), ('num_examples', 8000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Starting round 3 of federated learning...\n",
            "Round 3 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.5815), ('loss', 0.6813087), ('num_examples', 8000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Starting round 4 of federated learning...\n",
            "Round 4 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.58425), ('loss', 0.67992735), ('num_examples', 8000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Starting round 5 of federated learning...\n",
            "Round 5 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.58475), ('loss', 0.67895263), ('num_examples', 8000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Starting round 6 of federated learning...\n",
            "Round 6 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.58475), ('loss', 0.67815405), ('num_examples', 8000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Starting round 7 of federated learning...\n",
            "Round 7 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.586875), ('loss', 0.6774433), ('num_examples', 8000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Starting round 8 of federated learning...\n",
            "Round 8 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.587375), ('loss', 0.67679834), ('num_examples', 8000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Starting round 9 of federated learning...\n",
            "Round 9 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.587875), ('loss', 0.67619824), ('num_examples', 8000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Starting round 10 of federated learning...\n",
            "Round 10 metrics: OrderedDict([('distributor', ()), ('client_work', OrderedDict([('train', OrderedDict([('binary_accuracy', 0.5875), ('loss', 0.67563945), ('num_examples', 8000), ('num_batches', 250)]))])), ('aggregator', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('finalizer', OrderedDict([('update_non_finite', 0)]))])\n",
            "Federated learning rounds completed successfully.\n",
            "Model saved locally at /tmp/Anwarul_model_updates.keras.\n",
            "Model saved to Google Drive with ID: 1bfQ8ur67d5-cUKw69PlXnk1Y5ICcbG2l.\n",
            "Loaded model weights from Google Drive.\n",
            "Weights loaded correctly and match the saved weights.\n",
            "Files found in the global server folder:\n",
            "Faisal_model_updates.keras (1bfQ8ur67d5-cUKw69PlXnk1Y5ICcbG2l)\n",
            "Faisal_model_updates.keras (1clHNtoqEq8RpedkChsljEOoGFO9h2fRp)\n",
            "Anwarul_model_updates.keras (1htIVl_rPN1PNY9VqiA_sTuujF56L29KI)\n",
            "model_Updates.keras (1dbhico6nbGxMV_WtES8VHLfikvT0u_EW)\n",
            "tff architecture.jpg (1dZHJIPkis5fc25eFkaG5akE2F6XrC0Tb)\n",
            "Decrypting model weights...\n",
            "Model weights decrypted successfully.\n",
            "Privacy is preserved!!\n"
          ]
        }
      ]
    }
  ]
}